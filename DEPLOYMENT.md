# Deployment Guide - Deep Work Station

## Overview

This guide covers the complete deployment pipeline for Deep Work Station using:
- Docker for containerization
- GitHub Actions for CI/CD
- GitHub Container Registry (GHCR) for image storage
- Kubernetes (K3s) for orchestration
- ArgoCD for GitOps deployment
- Traefik for ingress and SSL termination

## Prerequisites

### VPS Setup
- K3s cluster running on Hostinger VPS
- ArgoCD installed and configured
- Traefik ingress controller with Let's Encrypt
- GitHub Personal Access Token (PAT) with packages:read permission

### Repository Secrets
Configure these secrets in your GitHub repository:

```bash
# GitHub Settings > Secrets and variables > Actions
GITHUB_TOKEN  # Automatically provided by GitHub Actions
```

## Deployment Pipeline

### 1. GitHub Actions CI/CD

The pipeline automatically:
- Tests the frontend code
- Builds a multi-platform Docker image
- Pushes to GHCR
- Updates Kubernetes manifests
- Triggers ArgoCD sync

**Triggered by:** Push to `main` branch

### 2. Docker Image

Multi-stage build optimized for production:
- Node.js 20 Alpine for building
- Nginx Alpine for serving
- Security hardening included
- Health checks configured

**Image location:** `ghcr.io/codincloud/deep-work-station`

### 3. Kubernetes Deployment

Uses Kustomize for environment-specific configurations:

```
deploy/
├── base/                    # Base configurations
│   ├── deployment.yaml      # Application deployment
│   ├── service.yaml         # Service definition
│   ├── ingress.yaml         # Traefik ingress
│   ├── middleware.yaml      # Security headers
│   └── kustomization.yaml   # Base kustomization
└── overlays/
    ├── production/          # Production overrides
    └── staging/             # Staging overrides
```

### 4. ArgoCD GitOps

ArgoCD monitors the repository and automatically syncs changes:
- Production: `main` branch → `deploy/overlays/production`
- Staging: `develop` branch → `deploy/overlays/staging`

## Manual Deployment Steps

### 1. Setup GitHub Container Registry Access

```bash
# On your K3s cluster, create a secret for GHCR access
kubectl create secret docker-registry ghcr-secret \
  --docker-server=ghcr.io \
  --docker-username=YOUR_GITHUB_USERNAME \
  --docker-password=YOUR_GITHUB_PAT \
  --namespace=deep-work-station
```

### 2. Deploy ArgoCD Applications

```bash
# Apply ArgoCD application configurations
kubectl apply -f argocd/application.yaml
kubectl apply -f argocd/application-staging.yaml
```

### 3. Update Domain Configuration

Edit the ingress patches with your actual domain:

```bash
# Production
vim deploy/overlays/production/ingress-patch.yaml
# Change: deepwork.your-domain.com

# Staging  
vim deploy/overlays/staging/ingress-patch.yaml
# Change: staging-deepwork.your-domain.com
```

### 4. Configure DNS

Point your domain(s) to your VPS IP:
```
deepwork.your-domain.com → YOUR_VPS_IP
staging-deepwork.your-domain.com → YOUR_VPS_IP
```

## Local Development with Docker

### Build and run locally:
```bash
# Build the image
docker build -t deep-work-station .

# Run with docker-compose
docker-compose up

# Access at http://localhost:3000
```

### Test the production build:
```bash
# Build production target
docker build --target production -t deep-work-station:prod .

# Run production image
docker run -p 8080:80 deep-work-station:prod

# Access at http://localhost:8080
```

## Monitoring and Troubleshooting

### Check deployment status:
```bash
# ArgoCD applications
kubectl get applications -n argocd

# Deployment status
kubectl get deployments -n deep-work-station

# Pod logs
kubectl logs -f deployment/deep-work-station -n deep-work-station

# Ingress status
kubectl get ingress -n deep-work-station
```

### ArgoCD UI Access:
```bash
# Port forward to access ArgoCD UI
kubectl port-forward svc/argocd-server -n argocd 8080:443

# Access at https://localhost:8080
# Default credentials: admin / <auto-generated-password>
```

### Get ArgoCD admin password:
```bash
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d
```

## Security Features

- **Container Security**: Non-root user, read-only filesystem, dropped capabilities
- **Network Security**: TLS termination, security headers via Traefik middleware  
- **Image Security**: Vulnerability scanning with Trivy in CI/CD
- **Access Control**: RBAC via Kubernetes, secret management

## Scaling and Performance

- **Horizontal Scaling**: Adjust replica count in overlays
- **Resource Limits**: CPU/Memory limits configured per environment
- **Caching**: Nginx optimized for static assets
- **Health Checks**: Liveness and readiness probes configured

## Backup and Recovery

- **Image Versions**: All builds tagged with git SHA for rollback
- **Kubernetes State**: ArgoCD provides declarative state management
- **Configuration**: All configs stored in git (GitOps)

---

# ADR: ArgoCD GitOps Setup with Let's Encrypt Integration

## Decision Record

**Date**: August 2025  
**Status**: Implemented  
**Context**: Deployment of Deep Work Station with ArgoCD + cert-manager integration

## Problem Statement

Setting up ArgoCD for GitOps deployment on a K3s cluster with existing Traefik ingress controller and cert-manager for SSL certificate management.

## Decision Drivers

- Existing K3s cluster with Traefik (not disabled)
- Pre-existing cert-manager with Let's Encrypt issuers configured
- Need for automated GitOps deployment
- SSL termination requirement
- Single production environment (no staging needed)

## Decisions Made

### 1. **ArgoCD Configuration Strategy**
- **Decision**: Configure ArgoCD to run in "insecure" mode behind Traefik proxy
- **Rationale**: Avoids SSL/TLS conflicts between ArgoCD's internal HTTPS and Traefik termination
- **Implementation**: 
  ```yaml
  server.insecure: "true"
  url: "https://argocd.codincloud.net"
  ```

### 2. **SSL Certificate Management**
- **Decision**: Use existing cert-manager with Let's Encrypt, NOT Traefik middleware
- **Rationale**: 
  - cert-manager provides better certificate lifecycle management
  - Avoids Traefik CRD dependencies
  - Cleaner separation of concerns
- **Implementation**: Standard ingress annotations with cert-manager.io/cluster-issuer

### 3. **Deployment Structure Simplification**
- **Decision**: Single production deployment, no overlay complexity
- **Rationale**: Project doesn't require staging environment
- **Implementation**: 
  ```
  deploy/manifests/  # Direct deployment manifests
  ├── deployment.yaml (3 replicas, production resources)
  ├── service.yaml
  ├── ingress.yaml (deepwork.codincloud.net)
  └── kustomization.yaml
  ```

## Implementation Challenges & Solutions

### Challenge 1: Traefik Middleware CRD Not Found
**Problem**: ArgoCD sync failed with "no matches for kind 'Middleware'"
```
Error: no matches for Id Deployment.v1.apps/deep-work-station.[noNs]
failed to find unique target for patch
```

**Solution**: 
- Removed Traefik middleware dependencies
- Used standard Kubernetes ingress with cert-manager annotations
- Simplified ingress configuration

### Challenge 2: Kustomize Deprecated Syntax
**Problem**: Kustomize warnings about deprecated fields
```
Warning: 'commonLabels' is deprecated. Please use 'labels' instead
Warning: 'patchesStrategicMerge' is deprecated. Please use 'patches' instead
```

**Solution**: Updated to modern Kustomize syntax, but later simplified to avoid complexity

### Challenge 3: ArgoCD SSL Redirect Loops
**Problem**: `ERR_TOO_MANY_REDIRECTS` when accessing ArgoCD UI
**Root Cause**: Both ArgoCD and Traefik trying to handle SSL termination

**Solution**:
```yaml
# ArgoCD ConfigMap
server.insecure: "true"  # Let Traefik handle SSL

# Ingress configuration
traefik.ingress.kubernetes.io/redirect-scheme: "https"
cert-manager.io/cluster-issuer: "letsencrypt-prod"
```

### Challenge 4: Docker Context Path Issues
**Problem**: Dockerfile couldn't find nginx.conf when moved to frontend/ directory
**Solution**: Reorganized Docker build context and file paths

## Key Configuration Files

### ArgoCD Application
```yaml
# argocd/application.yaml
spec:
  source:
    repoURL: https://github.com/j0hnroger/deep-work-station.git
    path: deploy/manifests  # Simplified path
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
```

### ArgoCD Ingress with cert-manager
```yaml
# argocd/argocd-ingress.yaml
annotations:
  cert-manager.io/cluster-issuer: "letsencrypt-prod"
  traefik.ingress.kubernetes.io/redirect-scheme: "https"
spec:
  tls:
  - hosts: [argocd.codincloud.net]
    secretName: argocd-tls
```

## Operational Outcomes

### Successes
- ✅ **GitOps Pipeline**: Fully automated deployment on git push
- ✅ **SSL Integration**: Seamless cert-manager + Let's Encrypt integration
- ✅ **High Availability**: 3 replicas with rolling updates
- ✅ **Monitoring**: ArgoCD UI accessible at https://argocd.codincloud.net
- ✅ **Application Access**: https://deepwork.codincloud.net

### Metrics
- **Deployment Time**: ~2-3 minutes from git push to live
- **Certificate Issuance**: ~30 seconds with existing ACME account
- **Resource Usage**: 128Mi/100m per pod (production-ready)

## Lessons Learned

1. **Keep SSL Simple**: Let one component handle SSL termination (Traefik + cert-manager)
2. **Avoid Over-Engineering**: Single environment doesn't need complex overlays
3. **CRD Dependencies**: Check for required CRDs before using advanced features
4. **ArgoCD Behind Proxy**: Always use `server.insecure: true` behind SSL proxy

## Future Considerations

- **Monitoring**: Add Prometheus metrics for ArgoCD sync status
- **Backup**: Implement ArgoCD configuration backup strategy
- **Security**: Consider ArgoCD RBAC for team access
- **Scalability**: Multi-cluster support if expanding beyond single VPS

---

## Next Steps

1. **Monitoring**: Add Prometheus/Grafana for observability
2. **Logging**: Configure centralized logging with Loki
3. **Alerting**: Setup alerting for application and infrastructure
4. **Performance**: Add CDN for global asset delivery
5. **Security**: Implement network policies and Pod Security Standards